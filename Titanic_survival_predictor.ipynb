{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Titanic_survival_predictor.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPsE8dJV2qtNqrDmd4WSiZ3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"b-n2wDple-KJ","executionInfo":{"status":"ok","timestamp":1621174447270,"user_tz":-330,"elapsed":1473,"user":{"displayName":"Yogesh Garg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzYjcKGNcWCyGx57VJAFkcRDlaaaTxsAab6nEO=s64","userId":"03278745799048091082"}}},"source":["%tensorflow_version 2.x"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"2kvK184flrZt","executionInfo":{"status":"ok","timestamp":1621174449836,"user_tz":-330,"elapsed":4031,"user":{"displayName":"Yogesh Garg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzYjcKGNcWCyGx57VJAFkcRDlaaaTxsAab6nEO=s64","userId":"03278745799048091082"}}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","from six.moves import urllib\n","\n","import tensorflow.compat.v2.feature_column as fc\n","\n","import tensorflow as tf"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A2HxW8Shn4_5","executionInfo":{"status":"ok","timestamp":1621174449842,"user_tz":-330,"elapsed":4031,"user":{"displayName":"Yogesh Garg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzYjcKGNcWCyGx57VJAFkcRDlaaaTxsAab6nEO=s64","userId":"03278745799048091082"}},"outputId":"c735c363-1b62-4d3a-f414-5a6d2392a15c"},"source":["dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n","dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\n","y_train = dftrain.pop('survived')\n","y_eval = dfeval.pop('survived')\n","\n","CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n","                       'embark_town', 'alone']\n","NUMERICAL_COLUMNS = ['age', 'fare']\n","\n","feature_columns = []\n","for feature_name in CATEGORICAL_COLUMNS:\n","  vocabulary = dftrain[feature_name].unique()\n","  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n","\n","for feature_name in NUMERICAL_COLUMNS:\n","  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n","\n","print(feature_columns)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(1, 0, 3, 4, 2, 5, 8), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='parch', vocabulary_list=(0, 1, 2, 5, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0), NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N8xlbo3ws5pY","executionInfo":{"status":"ok","timestamp":1621174569656,"user_tz":-330,"elapsed":9177,"user":{"displayName":"Yogesh Garg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzYjcKGNcWCyGx57VJAFkcRDlaaaTxsAab6nEO=s64","userId":"03278745799048091082"}},"outputId":"85613a42-31f1-4201-d508-58867aa4c26a"},"source":["def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n","  def input_function():  # inner function, this will be returned\n","    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its label\n","    if shuffle:\n","      ds = ds.shuffle(1000)  # randomize order of data\n","    ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs\n","    return ds  # return a batch of the dataset\n","  return input_function  # return a function object for use\n","\n","train_input_fn = make_input_fn(dftrain, y_train)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\n","eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)\n","\n","linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n","# We create a linear estimtor by passing the feature columns we created earlier\n","\n","linear_est.train(train_input_fn)  # train\n","result = linear_est.evaluate(eval_input_fn)  # get model metrics/stats by testing on tetsing data\n","\n","clear_output()  # clears consoke output\n","print(result['accuracy'])  # the result variable is simply a dict of stats about our model\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["0.75\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FOyjtX5nhiP0","executionInfo":{"status":"ok","timestamp":1621174952246,"user_tz":-330,"elapsed":2095,"user":{"displayName":"Yogesh Garg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzYjcKGNcWCyGx57VJAFkcRDlaaaTxsAab6nEO=s64","userId":"03278745799048091082"}},"outputId":"6a1b250c-32ba-451e-cb33-366d3c7bf357"},"source":["result = list(linear_est.predict(eval_input_fn))\n","print(result[0]['probabilities'])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n","  warnings.warn('`layer.add_variable` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /tmp/tmpqjl1ziar/model.ckpt-200\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","[0.9185274  0.08147258]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4Jh2MeR9jHQd"},"source":[""],"execution_count":null,"outputs":[]}]}